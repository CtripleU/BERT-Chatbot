{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5be6d85-2c95-44e7-8d8d-37410f2d0b66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d24a4e05-b65f-4ca4-9a81-2983a36e721c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7dd8aa2b0141bf8120f8227a29cf9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee352974d2e414bbd89367cf070ef54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa310b4050a54edfb789a52bb498337c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b1e92791c1440d68527cca966709db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ccec8919d24ec8845cdd040ab4ca32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "668eb32332b14d4bb917732dbc65f714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/cuda/__init__.py:616: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3300' max='3300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3300/3300 2:23:44, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9.303400</td>\n",
       "      <td>9.551639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9.302000</td>\n",
       "      <td>9.971188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9.159600</td>\n",
       "      <td>11.001689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='138' max='138' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [138/138 00:57]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 9.55163860321045, 'eval_runtime': 58.0593, 'eval_samples_per_second': 18.946, 'eval_steps_per_second': 2.377, 'epoch': 3.0}\n",
      "Instruction: If you are a doctor, please answer the medical questions based on the patient's description.\n",
      "Input: I have a headache and fever. What should I do?\n",
      "Predicted Response: Hi... Thank you for consulting in Chat Doctor. Skin conditions are best diagnosed only after seeing directly. I suggest you to upload photographs of the same on this website, so that I can guide you scientifically.  Hope my answer was helpful for you.  I am happy to help any time. Further clarifications and consultations on Chat Doctor are welcome. If you do not have any clarifications, you can close the discussion and rate the answer. Wish your kid good health.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load dataset\n",
    "ds = load_dataset(\"lavita/ChatDoctor-HealthCareMagic-100k\")\n",
    "\n",
    "# # Shuffle and select a subset of the data\n",
    "# full_dataset = ds['train'].shuffle(seed=42).select(range(11000))\n",
    "\n",
    "# Select the first 15000 rows of the dataset\n",
    "full_dataset = ds['train'].select(range(15000))\n",
    "\n",
    "# Split the data\n",
    "train_testvalid = full_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=0.5, seed=42)\n",
    "\n",
    "train_dataset = train_testvalid['train']\n",
    "val_dataset = test_valid['train']\n",
    "test_dataset = test_valid['test']\n",
    "\n",
    "# Extract unique outputs to use as labels\n",
    "unique_labels = list(set(train_dataset['output'] + val_dataset['output'] + test_dataset['output']))\n",
    "\n",
    "# Create a label mapping\n",
    "label_mapping = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "# Function to map text labels to numeric labels\n",
    "def map_labels(example):\n",
    "    example['label'] = label_mapping[example['output']]\n",
    "    return example\n",
    "\n",
    "# Apply the label mapping\n",
    "train_dataset = train_dataset.map(map_labels)\n",
    "val_dataset = val_dataset.map(map_labels)\n",
    "test_dataset = test_dataset.map(map_labels)\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    inputs = [f\"{inst} {inp}\" for inst, inp in zip(examples['instruction'], examples['input'])]\n",
    "    tokenized_inputs = tokenizer(inputs, truncation=True, padding=\"max_length\", max_length=512)\n",
    "    tokenized_inputs[\"labels\"] = examples[\"label\"]\n",
    "    return tokenized_inputs\n",
    "\n",
    "# Tokenize datasets\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val = val_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Format for PyTorch\n",
    "tokenized_train.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "tokenized_val.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "tokenized_test.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# Define model\n",
    "num_labels = len(label_mapping)\n",
    "model = BertForSequenceClassification.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\", num_labels=num_labels)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "# Define a custom Trainer to calculate loss\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        if labels is None:\n",
    "            raise ValueError(\"Labels should not be None\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation results: {eval_results}\")\n",
    "\n",
    "# Function to generate response category\n",
    "def predict_category(instruction, input_text):\n",
    "    inputs = tokenizer(f\"{instruction} {input_text}\", return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_class_id = torch.argmax(logits, dim=-1).item()\n",
    "    predicted_label = list(label_mapping.keys())[list(label_mapping.values()).index(predicted_class_id)]\n",
    "    return predicted_label\n",
    "\n",
    "# Test the model with a sample input\n",
    "sample_instruction = \"If you are a doctor, please answer the medical questions based on the patient's description.\"\n",
    "sample_input = \"I have a headache and fever. What should I do?\"\n",
    "predicted_label = predict_category(sample_instruction, sample_input)\n",
    "print(f\"Instruction: {sample_instruction}\")\n",
    "print(f\"Input: {sample_input}\")\n",
    "print(f\"Predicted Response: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046c7e40-9eab-4418-a0ab-30e6efba0cbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab22f72c-a1a1-47ad-a263-e03a3ae94873",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
